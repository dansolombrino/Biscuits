data:
  _target_: biscuits.data.datamodule.MyDataModule

  datasets:
    train_set:
      _target_: biscuits.data.dataset.CIFAR10Dataset
      # path: /home/dansolombrino/GitHub/biscuits/data
      path: ${oc.env:TRAIN_DATASET_PATH}
      train: True
      #split: 80

    val_set:
      _target_: biscuits.data.dataset.CIFAR10Dataset
      path: ${oc.env:VAL_DATASET_PATH}
      train: False

    test_set:
      _target_: biscuits.data.dataset.CIFAR10Dataset
      path: ${oc.env:TEST_DATASET_PATH}
      train: False
      #split: 20

  gpus: ${train.trainer.gpus}

  num_workers:
    train: 16
    val: 8
    test: 8

  batch_size:
    train: 128
    val: 128
    test: 128

  # example
  val_percentage: 0.2

module:
  _target_: biscuits.pl_modules.pl_module.MyLightningModule

  model:
    basic_resnet:
      _target_: biscuits.modules.Basic_ResNet
      resnet_depth: 14

  optimizer:
    #  Adam-oriented deep learning
    # _target_: torch.optim.Adam
    # #  These are all default parameters for the Adam optimizer
    # lr: 0.001
    # betas: [ 0.9, 0.999 ]
    # eps: 1e-08
    # weight_decay: 0

    _target_: torch.optim.SGD
    lr: 0.1
    momentum: 0.9
    weight_decay: 1e-4

  # lr_scheduler:
  #   _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
  #   T_0: 10
  #   T_mult: 2
  #   eta_min: 0 # min value for the lr
  #   last_epoch: -1
  #   verbose: False
